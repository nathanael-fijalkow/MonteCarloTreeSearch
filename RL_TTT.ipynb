{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement learning algorithms for Tic-Tac-Toe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class State is used to represent a configuration of the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from math import log, sqrt\n",
    "\n",
    "SIZE = 3\n",
    "\n",
    "class State(object):\n",
    "    def __init__(self):\n",
    "        # @data is a SIZE * SIZE array where\n",
    "        # 0 represents an empty position\n",
    "        # 1 represents a cross (symbol for player 1)\n",
    "        # 2 represents a circle (symbol for player 2)\n",
    "        self.data = np.zeros((SIZE, SIZE))\n",
    "        # @player: who's turn it is to play from this state\n",
    "        self.player = 1\n",
    "        self.hash = 0\n",
    "        # @outcome can be\n",
    "        # 1 if Player 1 wins\n",
    "        # 0 if Player 2 wins\n",
    "        # 0.5 if it's a tie\n",
    "        # -1 if the game is not over\n",
    "        # 2 if the outcome has never been computed\n",
    "        self.outcome = 2\n",
    "\n",
    "    # Checks whether the game is over from this state and who won\n",
    "    def compute_outcome(self):\n",
    "        if self.outcome != 2:\n",
    "            return self.outcome\n",
    "        else:\n",
    "            # Checks rows\n",
    "            for i in range(0, SIZE):\n",
    "                if all(x == 1 for x in self.data[i, :]):\n",
    "                    self.outcome = 1\n",
    "                    return 1\n",
    "                if all(x == 2 for x in self.data[i, :]):\n",
    "                    self.outcome = 0\n",
    "                    return 0\n",
    "\n",
    "            # Checks columns\n",
    "            for j in range(0, SIZE):\n",
    "                if all(x == 1 for x in self.data[:, j]):\n",
    "                    self.outcome = 1\n",
    "                    return 1\n",
    "                if all(x == 2 for x in self.data[:, j]):\n",
    "                    self.outcome = 0\n",
    "                    return 0\n",
    "\n",
    "            # Checks diagonals\n",
    "            diag = [self.data[i,i] for i in range(0, SIZE)]\n",
    "            if all(x == 1 for x in diag):\n",
    "                self.outcome = 1\n",
    "                return 1\n",
    "            if all(x == 2 for x in diag):\n",
    "                self.outcome = 0\n",
    "                return 0\n",
    "\n",
    "            anti_diag = [self.data[i,SIZE - 1 - i] for i in range(0, SIZE)]\n",
    "            if all(x == 1 for x in anti_diag):\n",
    "                self.outcome = 1\n",
    "                return 1\n",
    "            if all(x == 2 for x in anti_diag):\n",
    "                self.outcome = 0\n",
    "                return 0\n",
    "\n",
    "            # Checks whether it's a tie\n",
    "            data_all = [self.data[i,j] for i in range(0, SIZE) for j in range(0, SIZE)]\n",
    "            if all(x != 0 for x in data_all):\n",
    "                self.outcome = 0.5\n",
    "                return 0.5\n",
    "\n",
    "            # If we reached this point the game is still going on\n",
    "            self.outcome = -1\n",
    "            return -1\n",
    "\n",
    "    # Prints the board\n",
    "    def print_state(self):\n",
    "        for i in range(0, SIZE):\n",
    "            print('-------------')\n",
    "            out = '| '\n",
    "            for j in range(0, SIZE):\n",
    "                if self.data[i, j] == 1:\n",
    "                    token = 'x'\n",
    "                elif self.data[i, j] == 2:\n",
    "                    token = 'o'\n",
    "                else:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('-------------')\n",
    "\n",
    "    # Takes a state and returns the full list of moves that are legal moves\n",
    "    def legal_plays(self):\n",
    "        legal = []\n",
    "        for i in range(0, SIZE):\n",
    "            for j in range(0, SIZE):\n",
    "                if self.data[i, j] == 0:\n",
    "                    legal.append((i,j))\n",
    "        return legal\n",
    "\n",
    "    # Actually not useful because hashes are computed recursively\n",
    "    def compute_hash(self):\n",
    "        self.hash = 0\n",
    "        for i in self.data.reshape(SIZE * SIZE):\n",
    "            self.hash = self.hash * 3 + i\n",
    "        return self.hash\n",
    "\n",
    "    # Compute the hash of the state obtained by playing in (i,j)\n",
    "    def update_hash(self, i, j):\n",
    "        return self.hash + 3 ** (SIZE * i + j) * self.player\n",
    "\n",
    "    # Returns a new state obtained by playing in (i,j)\n",
    "    def next_state(self, i, j):\n",
    "        new_state = State()\n",
    "        new_state.data = np.copy(self.data)\n",
    "        new_state.data[i, j] = self.player\n",
    "        new_state.hash = self.update_hash(i,j)\n",
    "        new_state.player = 3 - self.player\n",
    "        return new_state\n",
    "\n",
    "    # Updates the same state by playing in (i,j)\n",
    "    def update_state(self, i, j):\n",
    "        self.data[i, j] = self.player\n",
    "        self.hash = self.update_hash(i,j)\n",
    "        self.player = 3 - self.player\n",
    "        self.outcome = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class Player implements the different algorithms for constructing a strategy.\n",
    "\n",
    "There are two main choices:\n",
    "* what strategy is used during training: 'epsilon-greedy' or 'UCB'\n",
    "* how do we update estimates: 'average' or 'step_size' or 'TD'\n",
    "\n",
    "### Strategies\n",
    "The **epsilon-greedy** strategy plays at random with probability epsilon, and maximises or minimises the current value otherwise.\n",
    "\n",
    "The **UCB (Upper Confidence Bound)** strategy uses the UCB formula which induces a tradeoff between exploration and exploitation. From a state if all available moves have been explored the strategy chooses the move which maximises or minimises the sum of two terms, one being the current value and the other one indicating how precise is the current value estimate. \n",
    "The parameter 'UCB' controls the exploitation.\n",
    "\n",
    "### Estimates updates\n",
    "The **average** update simply computes for a state the average over all plays containing this state of the outcomes.\n",
    "\n",
    "The **step_size** update changes the value using a step size instead.\n",
    "\n",
    "The **TD (Temporal Difference)** update values locally based on the current value estimates of the next state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player():\n",
    "    def __init__(self, name = '', strategy ='epsilon-greedy', update_mode = 'average',\n",
    "                 epsilon = 0.25, UCB = 1.4, step_size = 0.1, exponent = 0):\n",
    "        self.values = dict()\n",
    "        self.name = name\n",
    "        # @plays counts for each state how many plays included this state\n",
    "        self.plays = dict()\n",
    "\n",
    "        # What strategy are we using during training: 'epsilon-greedy' or 'UCB'\n",
    "        self.strategy = strategy\n",
    "\n",
    "        # How do we update estimates: 'average' or 'step_size' or 'TD'\n",
    "        self.update_mode = update_mode\n",
    "\n",
    "        # Parameters\n",
    "        self.epsilon = epsilon\n",
    "        self.UCB = UCB\n",
    "        self.step_size = step_size\n",
    "        self.exponent = exponent\n",
    "\n",
    "    # Takes the state and returns the move to be applied\n",
    "    def play(self, state, verbose = False):\n",
    "        if not state.hash in self.values:\n",
    "            if verbose:\n",
    "                print(\"The player had never seen that state!\")\n",
    "            return random.choice(state.legal_plays())\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"%s player's turn as player %d.\\nCurrent value: %0.5f\"  % (self.name, state.player, self.values[state.hash]))\n",
    "                print(\"Available moves and their values:\")\n",
    "                print([((i,j),self.values[state.update_hash(i,j)]) for (i,j) in state.legal_plays()\n",
    "                       if state.update_hash(i,j) in self.values])\n",
    "\n",
    "            # For more fun, we randomise over the most interesting moves\n",
    "            if state.player == 1:\n",
    "                evaluated_moves = [(self.values[state.update_hash(i,j)], (i,j)) for (i, j) in state.legal_plays()\n",
    "                                   if state.update_hash(i,j) in self.values]\n",
    "                max_val, _ = max(evaluated_moves)\n",
    "                interesting_moves = [(i, j) for (v,(i, j)) in evaluated_moves if v == max_val]\n",
    "            else:\n",
    "                evaluated_moves = [(self.values[state.update_hash(i,j)], (i,j)) for (i, j) in state.legal_plays()\n",
    "                                   if state.update_hash(i,j) in self.values]\n",
    "                min_val, _ = min(evaluated_moves)\n",
    "                interesting_moves = [(i, j) for (v,(i, j)) in evaluated_moves if v == min_val]\n",
    "            return random.choice(interesting_moves)\n",
    "\n",
    "    # Computes the (exact) values recursively\n",
    "    def solve(self, state = State()):\n",
    "        if state.compute_outcome() != -1:\n",
    "            self.values[state.hash] = state.outcome\n",
    "        else:\n",
    "            if state.player == 1:\n",
    "                current_val = 0\n",
    "                for (i,j) in state.legal_plays():\n",
    "                    next = state.next_state(i,j)\n",
    "                    if not (next.hash in self.values):\n",
    "                        self.solve(next)\n",
    "                    current_val = max(current_val,self.values[next.hash])\n",
    "                self.values[state.hash] = current_val\n",
    "            else:\n",
    "                current_val = 1\n",
    "                for (i,j) in state.legal_plays():\n",
    "                    next = state.next_state(i,j)\n",
    "                    if not (next.hash in self.values):\n",
    "                        self.solve(next)\n",
    "                    current_val = min(current_val,self.values[next.hash])\n",
    "                self.values[state.hash] = current_val\n",
    "\n",
    "    # During training, takes the current state and returns the move to be applied\n",
    "    def play_during_training(self, state, t):\n",
    "        if self.strategy == 'epsilon-greedy':\n",
    "            # Play the epsilon-greedy strategy\n",
    "            if random.random() < self.epsilon / (t ** self.exponent):\n",
    "                return (False,random.choice(state.legal_plays()))\n",
    "            else:\n",
    "                possible_states = [((i, j), state.update_hash(i, j)) for (i, j) in state.legal_plays()]\n",
    "                if all(hash_val in self.plays for ((i, j), hash_val) in possible_states):\n",
    "                    # If we have seen all of the legal moves at least once, we use the value\n",
    "                    if state.player == 1:\n",
    "                        _, (i, j) = max((self.values[hash_val], (i, j)) for ((i, j), hash_val) in possible_states)\n",
    "                    else:\n",
    "                        _, (i, j) = min((self.values[hash_val], (i, j)) for ((i, j), hash_val) in possible_states)\n",
    "                else:\n",
    "                    # Otherwise choose randomly among unevaluated moves\n",
    "                    unevaluated_moves = [(i, j) for (i, j) in state.legal_plays() if\n",
    "                                         not state.update_hash(i,j) in self.values]\n",
    "                    (i, j) = random.choice(unevaluated_moves)\n",
    "                return (True,(i,j))\n",
    "        if self.strategy == 'UCB':\n",
    "            # Play the UCB strategy\n",
    "            possible_states = [((i, j), state.update_hash(i,j)) for (i, j) in state.legal_plays()]\n",
    "            if all(hash_val in self.plays for ((i, j), hash_val) in possible_states):\n",
    "                # If we have seen all of the legal moves at least once, we use the UCB bound\n",
    "                if state.player == 1:\n",
    "                    _, (i, j) = max(\n",
    "                        (self.values[hash_val] +\n",
    "                         self.UCB * sqrt(log(self.plays[state.hash]) / self.plays[hash_val]), (i, j))\n",
    "                        for ((i, j), hash_val) in possible_states)\n",
    "                else:\n",
    "                    _, (i, j) = min(\n",
    "                        (self.values[hash_val] -\n",
    "                         self.UCB * sqrt(log(self.plays[state.hash]) / self.plays[hash_val]), (i, j))\n",
    "                        for ((i, j), hash_val) in possible_states)\n",
    "            else:\n",
    "                # Otherwise choose randomly among unevaluated moves\n",
    "                unevaluated_moves = [(i, j) for (i, j) in state.legal_plays() if\n",
    "                                     not state.update_hash(i,j) in self.plays]\n",
    "                (i, j) = random.choice(unevaluated_moves)\n",
    "            return (True, (i, j))\n",
    "\n",
    "    def store_new_state(self, state):\n",
    "        if not(state.hash in self.plays):\n",
    "            self.plays[state.hash] = 0\n",
    "            self.values[state.hash] = 0\n",
    "\n",
    "    def run_simulation(self, t):\n",
    "        state = State()\n",
    "        state.hash = 0\n",
    "        self.store_new_state(state)\n",
    "        self.plays[state.hash] += 1\n",
    "\n",
    "        # We store the play in a sequence\n",
    "        play = []\n",
    "\n",
    "        while state.compute_outcome() == -1:\n",
    "            greedy, (i, j) = self.play_during_training(state,t)\n",
    "            play.append((greedy,state.hash))\n",
    "            state.update_state(i, j)\n",
    "            self.store_new_state(state)\n",
    "            self.plays[state.hash] += 1\n",
    "\n",
    "        if self.update_mode == 'average':\n",
    "            # Update using average\n",
    "            self.values[state.hash] = state.outcome\n",
    "            for greedy,hash_val in play:\n",
    "                self.values[hash_val] += 1.0 / self.plays[state.hash] * (state.outcome - self.values[hash_val])\n",
    "\n",
    "        if self.update_mode == 'step_size':\n",
    "            # Update using step size\n",
    "            self.values[state.hash] = state.outcome\n",
    "            for greedy,hash_val in play:\n",
    "                self.values[hash_val] += self.step_size * (state.outcome - self.values[hash_val])\n",
    "\n",
    "        if self.update_mode == 'TD':\n",
    "            # Update using temporal difference (TD)\n",
    "            next_hash_val = state.hash\n",
    "            self.values[next_hash_val] = state.outcome\n",
    "            for greedy,hash_val in reversed(play):\n",
    "                if greedy:\n",
    "                    td_error = self.values[next_hash_val] - self.values[hash_val]\n",
    "                    self.values[hash_val] += self.step_size * td_error\n",
    "                next_hash_val = hash_val\n",
    "\n",
    "    def train(self, number_simulations, verbose = False):\n",
    "        if verbose:\n",
    "            print(\"Start training of Player %s\" % self.name)\n",
    "        for t in range(1,number_simulations+1):\n",
    "            self.run_simulation(t)\n",
    "            if verbose and t % 100 == 0:\n",
    "                print(\"After %d iterations the value of the initial state is %0.5f\" % (t, self.values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class Competition is used to play strategies against each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Competition(object):\n",
    "    # Saves the value function\n",
    "    def save_values(self, name, player):\n",
    "        with open('strategy_%s.bin' % name, 'wb') as f:\n",
    "            pickle.dump(player.values, f)\n",
    "\n",
    "    # Loads a value function\n",
    "    def load_values(self, name, player):\n",
    "        with open('strategy_%s.bin' % name, 'rb') as f:\n",
    "            player.values = pickle.load(f)\n",
    "\n",
    "    # Takes two strategies (one for each player), play them against each other once and declare an outcome\n",
    "    def play(self, player1, player2, verbose=False):\n",
    "        state = State()\n",
    "        state.hash = 0\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Match between Player %s (as Player 1) and Player %s (as Player 2)\" % (player1.name, player2.name)) \n",
    "\n",
    "        while state.compute_outcome() == -1:\n",
    "            if verbose:\n",
    "                state.print_state()\n",
    "            if state.player == 1:\n",
    "                i, j = player1.play(state, verbose)\n",
    "                state.update_state(i, j)\n",
    "                if verbose:\n",
    "                    print(\"Player %d chooses (%d,%d)\" % (1, i, j))\n",
    "            else:\n",
    "                i, j = player2.play(state, verbose)\n",
    "                state.update_state(i, j)\n",
    "                if verbose:\n",
    "                    print(\"Player %d chooses (%d,%d)\" % (2, i, j))\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Final state\")\n",
    "            state.print_state()\n",
    "            if state.outcome == 1:\n",
    "                print(\"Player 1 won\")\n",
    "            elif state.outcome == 0:\n",
    "                print(\"Player 2 won\")\n",
    "            else:\n",
    "                print(\"It's a tie!\")\n",
    "        return state.outcome\n",
    "\n",
    "    # Takes two strategies (one for each player) and play them against each other for a number of games\n",
    "    def compete(self, player1, player2, games = 500):\n",
    "        player1_win = 0.0\n",
    "        player2_win = 0.0\n",
    "        for _ in range(games):\n",
    "            outcome = self.play(player1,player2)\n",
    "            if outcome == 1:\n",
    "                player1_win += 1\n",
    "            if outcome == 0:\n",
    "                player2_win += 1\n",
    "        print(\"Competition results: %d plays, player 1 wins %.02f, player 2 wins %.02f\" % (games, player1_win / games, player2_win / games))\n",
    "\n",
    "    # Checks whether a player ensures ties against another player over a number of games\n",
    "    def ensures_tie(self, player1, player2, games = 50, player_of_interest = 1):\n",
    "        i = 0\n",
    "        while i < games:\n",
    "            if self.play(player1,player2) == player_of_interest - 1:\n",
    "                return i\n",
    "            i += 1\n",
    "        return games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate all the players (with default parameters).\n",
    "For convenience the value functions are loaded to avoid training each of them again.\n",
    "Uncomment for training them again and saving the value functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training of Player epsilon-greedy TD\n",
      "After 100 iterations the value of the initial state is 0.00007\n",
      "After 200 iterations the value of the initial state is 0.00151\n",
      "After 300 iterations the value of the initial state is 0.00503\n",
      "After 400 iterations the value of the initial state is 0.00672\n",
      "After 500 iterations the value of the initial state is 0.01012\n",
      "After 600 iterations the value of the initial state is 0.00759\n",
      "After 700 iterations the value of the initial state is 0.01188\n",
      "After 800 iterations the value of the initial state is 0.00690\n",
      "After 900 iterations the value of the initial state is 0.00494\n",
      "After 1000 iterations the value of the initial state is 0.00278\n",
      "After 1100 iterations the value of the initial state is 0.00232\n",
      "After 1200 iterations the value of the initial state is 0.00525\n",
      "After 1300 iterations the value of the initial state is 0.00219\n",
      "After 1400 iterations the value of the initial state is 0.00737\n",
      "After 1500 iterations the value of the initial state is 0.01426\n",
      "After 1600 iterations the value of the initial state is 0.02166\n",
      "After 1700 iterations the value of the initial state is 0.01491\n",
      "After 1800 iterations the value of the initial state is 0.02612\n",
      "After 1900 iterations the value of the initial state is 0.05769\n",
      "After 2000 iterations the value of the initial state is 0.09094\n",
      "After 2100 iterations the value of the initial state is 0.12517\n",
      "After 2200 iterations the value of the initial state is 0.16044\n",
      "After 2300 iterations the value of the initial state is 0.19351\n",
      "After 2400 iterations the value of the initial state is 0.22772\n",
      "After 2500 iterations the value of the initial state is 0.26628\n",
      "After 2600 iterations the value of the initial state is 0.30732\n",
      "After 2700 iterations the value of the initial state is 0.34570\n",
      "After 2800 iterations the value of the initial state is 0.38078\n",
      "After 2900 iterations the value of the initial state is 0.41076\n",
      "After 3000 iterations the value of the initial state is 0.43752\n",
      "After 3100 iterations the value of the initial state is 0.45439\n",
      "After 3200 iterations the value of the initial state is 0.47409\n",
      "After 3300 iterations the value of the initial state is 0.48686\n",
      "After 3400 iterations the value of the initial state is 0.49479\n",
      "After 3500 iterations the value of the initial state is 0.49790\n",
      "After 3600 iterations the value of the initial state is 0.49929\n",
      "After 3700 iterations the value of the initial state is 0.49966\n",
      "After 3800 iterations the value of the initial state is 0.49983\n",
      "After 3900 iterations the value of the initial state is 0.49992\n",
      "After 4000 iterations the value of the initial state is 0.49997\n",
      "After 4100 iterations the value of the initial state is 0.49999\n",
      "After 4200 iterations the value of the initial state is 0.50000\n",
      "After 4300 iterations the value of the initial state is 0.50000\n",
      "After 4400 iterations the value of the initial state is 0.50000\n",
      "After 4500 iterations the value of the initial state is 0.50000\n",
      "After 4600 iterations the value of the initial state is 0.50000\n",
      "After 4700 iterations the value of the initial state is 0.50000\n",
      "After 4800 iterations the value of the initial state is 0.50000\n",
      "After 4900 iterations the value of the initial state is 0.50000\n",
      "After 5000 iterations the value of the initial state is 0.50000\n",
      "Competition results: 500 plays, player 1 wins 0.00, player 2 wins 0.00\n"
     ]
    }
   ],
   "source": [
    "competition = Competition()\n",
    "\n",
    "player_optimal = Player()\n",
    "player_optimal.solve()\n",
    "#competition.save_values(\"optimal\", player_optimal)\n",
    "competition.load_values(\"optimal\", player_optimal)\n",
    "\n",
    "player_eps_average = Player(name='epsilon-greedy average sample', strategy='epsilon-greedy', update_mode='average')\n",
    "player_eps_step_size = Player(name='epsilon-greedy step size', strategy='epsilon-greedy', update_mode='step_size')\n",
    "player_eps_td = Player(name='epsilon-greedy TD', strategy='epsilon-greedy', update_mode='TD')\n",
    "\n",
    "player_UCB_average = Player(name='UCB average sample', strategy='UCB', update_mode='average')\n",
    "player_UCB_step_size = Player(name='UCB step size', strategy='UCB', update_mode='step_size')\n",
    "player_UCB_td = Player(name='UCB TD', strategy='UCB', update_mode='TD')\n",
    "\n",
    "player_eps_td.train(5000, True)\n",
    "competition.compete(player_eps_td,player_optimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many iterations to ensure a tie against the optimal player?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def how_many_iterations(player,steps = 100, games = 500, verbose = False, player_of_interest = 1):\n",
    "    iteration = 0\n",
    "    while(True):\n",
    "        player.train(steps)\n",
    "        iteration += steps\n",
    "        if player_of_interest == 1:\n",
    "            result = competition.ensures_tie(player,player_optimal,games,player_of_interest)\n",
    "        else:\n",
    "            result = competition.ensures_tie(player_optimal,player,games,player_of_interest)\n",
    "        if result == games:\n",
    "            if verbose:\n",
    "                print(\"After %d iterations, Player %s ensured ties each of the %d matches\"\n",
    "                      % (iteration, player.name,games))\n",
    "            return iteration\n",
    "        elif verbose:\n",
    "            print(\"After %d iterations, Player %s lost the match number %d\" % (iteration, player.name, result))\n",
    "\n",
    "#how_many_iterations(player_eps_average, steps = 1000, games = 100, verbose = False)\n",
    "#how_many_iterations(player_eps_step_size, steps = 1000, games = 100, verbose = False)\n",
    "#how_many_iterations(player_eps_td, steps = 1000, games = 100, verbose = False)\n",
    "\n",
    "#how_many_iterations(player_UCB_average, steps = 1000, games = 100, verbose = False)\n",
    "#how_many_iterations(player_UCB_step_size, steps = 1000, games = 100, verbose = False)\n",
    "how_many_iterations(player_UCB_td, steps = 1000, games = 100, verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explore the influence of the different parameters for each of the players.\n",
    "Running the statistics takes a long time since we train a lot of players!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO29e5hsV13n/flVdfc5fS45SSDjg7l4whhHURlhjgjDjKMid0gYRWFGncCb940iAjOv7zvAeIkDeEFHGNDRhwjMG5HXcJGRiCjmiQQZh0tOuIQkEBMCSEKQQHJOktOnu+vymz/2rj67q6tqr732ulSf+n2ep5+urq7aa+2qvdd3/S7rt0RVMQzDMIxZdHJ3wDAMw5h/TCwMwzCMWkwsDMMwjFpMLAzDMIxaTCwMwzCMWpZydyAGD3/4w/Xw4cO5u2EYhrGruPHGG7+uqudM+t9pKRaHDx/m6NGjubthGIaxqxCRL037n7mhDMMwjFpMLAzDMIxaTCwMwzCMWkwsDMMwjFpMLAzDMIxaTCwMwzCMWkwsDMMwjFpOy3UWpxvPe9NHnF73jp9+QuSeGIaxqJhlsQu5+e7j3PqVB3J3wzCMBcIsi13AuMXwrDd+mL3LXbMkDMNIhlkWhmEYRi0mFoZhGEYtJhaGYRhGLSYWhmEYRi0mFoZhGEYtJhaGYRhGLSYWuxEpfwzDMBJhYrFLMa0wDCMlJhaGYRhGLbaCexeS2qoYr001VKUj23thq8kN4/TGLItdST4n1K33PMDNd1tdKsNYNMyyMGqpWg3Pe9NHOHayZ5aEYSwYZlkYhmEYtZhY7EIsc9YwjNSYWOxaTC4Mw0iHicVuJLdpoRnbNgwjCyYWhmEYRi0mFoYHZloYxqJhYrFLyeWFMpkwjMXExMIwDMOoxRbl7UIWKQ9qvNTINGyRoHG64XLtp7zuzbIwGpPTFXXLVx7glq8cz9gDw0jPrfc8wM2Zr3uzLIxmJFaK8ZnTc/7b39IbDM2SME57xsvsPLCet8yOWRZGQwq1UM1nX2Rs2jAWFhMLoxGjcdoGbMNYLEwsDC8y2hXZWjaMRcbEwvAilxuqaNYEw1gs5uGKN7EwvMh58c7DjWMYi4aJxS5kHgZLi1kYxmJhYmE0YiQSQ1MLw1goooqFiPwHEblFRG4WkT8Wkb0icqGIfExE7hCRd4jISvnaPeXfd5T/P1w5zivL528TkafG7PNuYVGHagtZGEYeoomFiJwLvBQ4oqrfBXSB5wOvBV6vqt8K3A9cVr7lMuD+8vnXl69DRB5Vvu87gacBvyci3Vj9Ntwwy8IwFovYK7iXgFUR6QH7gHuAHwL+bfn/q4BfAX4fuKR8DPBu4HdFRMrnr1bVDeALInIH8DjArWjQ6UqmsXrU7DCjVphMLQa564LNW22m3Bd+NMtCVe8G/gvw9xQicRy4ETimqv3yZXcB55aPzwW+XL63X77+YdXnJ7xnCxG5XESOisjRe++9N/wJzRFZ00dLi8IsCyM1n7nrOJ+5K099JC3bX+S6ZNEsCxE5i8IquBA4BryLwo0UBVW9ErgS4MiRI6f9SJbrBLdWcA8zd8A47anO2gdD5elv+BsArr788RROh3Ttb/aHPOt3Psy+lW6e+kxzcN3HDHD/MPAFVb1XVXvAe4AnAmeKyEikzgPuLh/fDZwPUP7/EPCN6vMT3rOg5L9yBrkW5WVp1chN1ZLN4QIdtZ/PoM5/5ccUi78HHi8i+8rYw5OAW4EPAs8tX3Mp8N7y8TXl35T//2stlglfAzy/zJa6ELgI+HjEfs8987AgLqcbKv9tY6RmMKyKxeJdAUr+6z6aG0pVPyYi7wY+AfSBT1K4if4cuFpEXlM+95byLW8B3lYGsO+jyIBCVW8RkXdSCE0feLGqDmL1e1eg+WY4W+sscka4jYWjer0Phspy4nzIBdSnHUTNhlLVK4Arxp6+kyKbafy168CPTTnOrwK/GryDu5R5uG7zuaEyKqWRjdzWhI5K82ftRV5sBfcuJVuAu7xp+4NFvm2M1GyPWaS/9uZhfpK7CyYWuxDVjFVfy9/ZZnqa/6Yx0lP9znN4QHNfc6pkVywTi12I5rx0y6b7mWMWFjNZLKqp2jkmSjl3htzqQ+b2TSx2IzkD3OUlm2uw1rHfxmJQnSBltSxyV07IOEkysdiF5EyjG4lUL3PMInfA00hLdYzMY1mUv5O3vL0DuRJLwMRiV7LQMYs5ad9IS3Y30Jw0PzDLwnBFVdGMUYtTlkWeeh9bMzzTioWi+nXn+O6zxgk5dc4mFoYzo8By7phFvos2d9kFIwfV7zv3ioucreZMLDGx2GWM1jfkmunkjlnMixvMyMcixixOrW/KVcHTQSxE5GUicoYUvEVEPiEiT0nROWMn/WFxseQr96Hb+pG+A8UvE4vFojo5yvHN577adotl8X+o6gPAU4CzgJ8CfiNqr4ypjGb0OcbK4fDULZtrBfepFMIszRsLimY2LUbt54oVgptYjArHPwN4m6reUnnOSMzIDM3hhupVRujBULPmfJtlsWBsS51N33zuNaDDzO5fcBOLG0XkryjE4gMichCweV0mNgf53FDj1kQvw/R+K4XQxMJIyLxkQ2328w29LlVnLwO+B7hTVddE5GHAC+N2y5jGKTeUoqpJdgw71fb2C7U/UPbE3sV9HNvWdSHJ/W3PS4A7pxuq9lZX1aGI/APwqMoOd0YmeltuqCLYtdxNKRbbb5XUcYtijUmBxSyMlOSem4zcUBv9fFv51A7+IvJa4HkUmw+NeqrA30TslzGFqhm62R+y3E2X/TyeAbWZeJZTXdthbqjFJYdLKOe2qr3BcOucN+bcDfUc4J+o6kbszswrz3vTR5xel2Ij9+oAvdkfsn9P9Ca36PXHLIvE0/uqQCxK1VmXay/mdZe7/Xkhp9uzOkGcd7G4E1gGFlYsxrn57uMAfNe5h5K3vc2ySDyzHw9oj4tHbKr36yLGLNY2+9x57wkAHvXNZ9BJFK9S4GSl7Uees59up8OepcVZ0zu69HNYNeu9U66nwUDpDdJ6FEa4iMUa8CkRuY6KYKjqS6P1as4Ynzk99fUfQoG3XfZ9rCS+YcbdUCnJnQ21zQ21IJbF6NrrDYZ86LZ7+c0PfA6AN1/6vRxaXU7S/tpmn/91xze22n7Zk76Nhx1Y4TEXnBW9/XlhkDHCPW5NbCR2P49wEYtryh+D7QvTUg9YqprVJJ2UDZWSbW6oBbMsxs83pRtuUm7/ooj1iNH55jjrqmUx+vtA8jREt2yoq0RkBfi28qnbVLUXt1vzS3XAKnz23WRt75xhpM2MGBeL1Gl81QFywcaqHYHVlGI5SRhy75SYmq0Ad4a2T04Qixy4ZEP9AHAV8EWKldvni8ilqrqQ2VA5XSGTzNGUjM8wU4tF9fPOVW4kFzssi4SnP+k6XzTLYut6y2DRrveGY3/PqVgAvw08RVVvAxCRbwP+GPhnMTs2r/SzisX2i2SjlzpmMeaGSnz+i+2G2v53ykCricV2N9RgqHQ76dY3jYvDyc08GVEuUZLlkVAAqOrfUWRHLSSDQUax6OV1Q41nX/USWzaLnA01XpY75elPWtOyaOtcqskcKS1qVd0pFnNsWRwVkTcDf1T+/RPA0Xhdmm+qawtSz6zHxaE/UPqDIUsJMiNUdYc49lJbFguYDTVi/GxTjtWTgunZtzlNTK5rb7033PFdz7NYvAh4MTBKlf0w8HvRejTnVGdUqQescd8lFHGLFGLRH+qOizb1RiyDBQ5w52SSLgyHJK9NlpOqFZ3SspgkDL3+MNkksYpLNtQG8LryZ+HJG+DeeeGs9wbsT5BGN+lcVdP6bxfbDZWv7WmftSqk0orcX3fVik5ZJnyaFXGyN+DgvIiFiLxTVX9cRD7DhIwxVX101J7NKdsycubEskjBtNlUbzCk20mTPpzTqps3Uga4p4nFUJVOjq1tEn/1qrrNik5qWWzOEIu9aUPHs6akLyt/PytFR3YL210h6a5aVZ1qWaRgWqpqSsEcZsiGmqe6YFUk4SA97SteFLnuDba7YFOKxbT7ez1DRtRUO0ZV7ykf/qyqfqn6A/xsmu7NH9XBMWWu/+ZgOLEs9yRrIwbTSnukjFtUA62p3RK9wZBja5vcdNcxbrrrGMfWNhdmsJwmC4viCsy5GHWWGyo1Ls7uJwMvH3vu6ROeWwiGGbMiJj6fKH122rmmtSxOPU712Y8shnuOn+SWux/Yqo/0/z712/kXFz2cvctpXHA548jTNCGlVlTdbqklarwGW8rFsLPcUKmZFbN4EYUF8UgRuanyr4PA38bu2LyybVFewrtlY5o5mtsNldC6yuGGGjHpPFNOFsa1IqV4zIP9UP26Uxs04+uLUhXwHAx1als5VnHPsiz+f+AvgF8HXlF5/kFVvS9qr+aY7dlQKX2Xk9tKNcuZZkGk3NOiKhCpB4xJ4pTSqhpPUU1paMyHZZGP8QE7lVjMWnSbQyxmxSyOq+oXVfXflHGKkxTf2QERuSBZD+eM7WKRrt1pF86ovn1spgljytl1ztTZScKQsvLrDnGYg+UNOfZ2yNFurppss+KRowW5KalN1BWRZ4vI7cAXgA9RFBT8i8j9mlu2BbjnwLIo/hd/ljHdsshTo0g17SriScKQ0g057nZKmQ2VSxS29SGjVTk+UesNhkmuvbr7OnUhUZdVHa8BHg/8napeCDwJ+GjUXs0xw0y5/rNM0hQXzbTYRMrPIGfl1UltpbRuxsUhacxiHtxQ1ZhFumaBnfeXapp7rq6N1K4oF7Hoqeo3gI6IdFT1g8CRyP2aW6qDZspZ9SzLIsWFOzUbKmmAe/zvPFbNVvsJJ3bj4pBqS1WYIRbJejAe4E7shsq0GLauUGjqbZVdxOKYiBwA/gZ4u4i8ATjhcnAROVNE3i0inxORz4rIE0TkbBG5VkRuL3+fVb5WROSNInKHiNwkIo+tHOfS8vW3i8ilPicaiqrrKZXPetqCvBEpZhjTXC6pFybmantSWznXGSQNcE+RhZSD9rbU2cxuqGnPhaYukJ56iwIXsbiEYh/u/wD8JfB54NmOx38D8Jeq+u3APwU+S5FZdZ2qXgRcx6lMq6cDF5U/lwO/DyAiZwNXAN8HPA64YiQwORj3m6cIMm30d1ae3Pb/BBfNNGFMaV2Nt5R7TVhKsRi3JObBDZWS4TbLIl27g6FOtJ5T3HN1YjFXloWIdIH3qepQVfuqepWqvrF0S81ERA4B3w+8BUBVN1X1GIX4XFW+7CrgOeXjS4A/1IKPAmeKyCOApwLXqup9qno/cC3wtOan2p5JZbpTDJZ1F0WKWc6080wZsxhvK7dlkXLQyhngnkbKmFHVikn5vU+7t1K4oeru+1QpvCNmioWqDoBhOfA35ULgXuC/i8gnReTNIrIf+KZKKZGvAt9UPj4X+HLl/XeVz017PjmDCWW6UwyWdbOYnDGLRQ5wJxWL2ifiMfU8M33+ScViWuWEBK7fuuq2qbc1din38RDwGRG5lkqsQlVfOv0tW8d+LPASVf1YGeuoLu5DVVVEgnzzInI5hfuKCy6Iswxk0uw6RYC3znJYFLEYHyNyWxZJs6EyuqGmlijPVPk25SRh2r2VJgNxdhupq167xCzeA/wSRYD7xspPHXcBd6nqx8q/300hHv9Qupcof3+t/P/dwPmV959XPjft+W2o6pWqekRVj5xzzjkO3WvOJCWfVmAvJHUXZq8/jB5snxbgzuqGyihUkDYbaEe5j4RtTzvPtJZdHjfUNAsituu3P5gdp4Q5tCxU9SoRWQUuqO7F7fC+r4rIl0Xkn5TvexJwa/lzKfAb5e/3lm+5Bvg5EbmaIph9XFXvEZEPAL9WCWo/BXilaz9CMsksTPGFufgmNwdD9kbaV0JVt+09XiXlwrTxQSKtVTNn2VAJTYtZ+1kk60PlFkgbs8hjWbhYDan3dKkVCxF5NvBfgBXgQhH5HuBVqnqxw/FfQpFuuwLcCbyQwpp5p4hcBnwJ+PHyte8HngHcQZF99UIAVb1PRF4N3FC+7lW5alNNtCz6CQLcDhfmRn8YrQLqrGsyZX2sHWKRNHVzwnMZA9wpmWbB5XIDzsNi2EFZbiPW1qYu55jaDeUSs/gVipTV6wFU9VMi8kiXg6vqp5i8gO9JE16rFHt9TzrOW4G3urQZk0mDdor0NZdZTHFRx9k5a1ZZk1R7MavqjkVwKRfFTRowF2WdxbQxKeXnv23TsYTtziyz0x9yIJJYOFkWCRfEgvsK7uNjz6XfpmkOmCQMKdLXXNqIuS9w3c2ZYoYzqY20LrCdz83D+oMUTE1uSLmCvmpZzEHqLEzfNiAErvG4lFaWi1jcIiL/FuiKyEUi8jvA/4rcr7kkl2WxOai/KGNeuHUFE1NcsJPaSDmzmhSzyLkPeMqWp8YsMiU3pHJ9qk7fTwLi3vuugjhvYvES4DuBDYo9Lo5zan/uhWKSOyjmIA1FnMTl3oh64dZckCku2EmWRYpMtBGTbt5F2VZ0HnZJzLE1wGZNRlLMLY1dhTjlNegSs3imqv4C8AujJ0Tkx4B3RevVnDJJGGJnRbi6uWK6w+oGhSRuqAkjRM603dTtj48JKesyzcMam+0FPFNtPpRvBbXrR5u05IzDayalqWZJXc3N+iQ3VOQ1DvMgFvNgWeRKWx4x6abMmTacquXhcGeJmxFJxaIiEKkqHddXTogYs3C8tlJ6Qmftwf10ilTWc0XkjZV/nQH0Y3ds3ugPhvSm7YfbH7BvxcVIa46reymrZZFg0J40m4wZ1K8yHO7MxBo9n4rxljSRTs4SxJRivd0NleZzr6/JFtOy2F1uqK8AR4GL2b5i+0GKCrQLxckZsYm1zYhi4WpZRLxx56HswKT1LKkGq2mxkVRiBZPqYqVpe9YsPlXMYnw182CoDIdKpxM3gbguHhnVDeV46FSTBpghFqr6aeDTIvJ2VV04S2KcWWJxcjOeOeo6e+kP4t1AdYNiCrfAJDGcZumFZtr5pdxWd8cak0RiMSuJINUe0NOSG/ZEqlgwou7emw831BxYFiLyTlX9ceCTk4r9qeqjo/ZszljbmG1ZxKLJ7CVWyY+6QTFFVtKkz2Ej1WA1RSySumEylTqZJcipLKtJn3N/oOyJY8xvUXfvDYdF35YjLMxzFYGUcbNZH/coPfZZKToy75zYnG5czfpfW5oMSLFKftRZDikGzUmzuNglF7banrLOZTgkSfuwUxxSDRKzBCGZGzBTcoNb5YRYYuH6ujkQi9GeE6r6pWS9mWNmWQ8nNuKJRZMgWqySH3XxkDRl2qcXdIs9WM8aMDcziUWqjKBZg3I6schVZsdtMeyBCCaOsxsqYcwi/lV+mvDQDEHY6A2j+W8buaEi+fBr9wJOEDuYXio6waAxI16Varey8esrVXB51qCsmq/qcmwXWN3q7RGxRMvVzZjSDWVi4cB6b1BbWmKWmPiiqk6lPkbEGjjrBoTYA0Z/MJw6k06xY9mszzWFWAH0dlgWadqt3Qc60/aisdutW709ItZe3K5ikTJ9e6pYiMh15e/XJuvNnPLger0QxBCL3mByfv80YtxALjOs2DfupMWQI2ZlqYViplhELPlQZTzQnCq4nPu7n9ZG7HZdJwGxJguuYpGy5MosZ9sjROSfAxeXGxJty8lU1U9E7dkc4SIELoLSlKapeTEuXJcZ1mZ/GLVM+dqMBIKYacsjZlkvKcQKdlpvqeIFdW6WJIU0c4iF4yQgVvqsqwik3E9mllj8MsV2qucBrxv7nwI/FKtT88aD673a18SwLJoO/jGKGrrelDE3X1rfzGtZzGojhRsMdl4LqdxftSUvElhWk861iXvWB9fvNVYxQVc3Y8qFobOyod4NvFtEfklVX52sR3OIkxtqvR98dt10QJjlrvHF9WbY6MUTi7Xe9M8/5hoXKMRyVrwqdvtb/RgbPFK4f1xiZrH3op7WRmyRcj2vWJMFVxFIudbHZQ/uV4vIxcD3l09dr6rvi9ut+aE3GDq5OgZD5cRm2DS6phdiryxqGHIVt/MMqz/gUKSd+mYNyL3+MNrCKKh3c53shZ8kTGL8e9joD6K3u+lQHj+2hTMtZha7XddJ0maEew7cRSClWNTeYSLy6xQL9G4tf14mIr8Wu2PzwkMNYhFNXuuCz6wl9E2Ue4YF9etYZq2ub912zYLL4TBR+u5YG6rx23U5fmw33EZ/csxsMNSoA2WT81oPbF0NZlT6HWdzQs20WLhMx54JPFlV31ruhf00FmhVd5PA9QMOsY0m+PhDQ9+8J2fEC7a9LtKg0R8Ma10OD0VcQT8ruD4i5qJMKGaPk1xhsQdql+PnFKyY59/keg6dZNHEtZfCDTjC1XY/s/L4UIyOzCtNBMAlEN4En4B16FmO600Ty3d/wuG4axEH6xMOVkvsuMW048cO7rvEBdZ7g6gbMc26B2IFlwdDbRQTCf39N2m7P3C3Qtri4mD/dYpigh+kSJ/9fuAVUXs1RzSxLEKnz/oM/KFvIJeZNcB6LLFwEIIYmWjz0j5Mn7nGFikXMRq5w6Jlws24nmNZFk1FOLRoN86CjLifThWXAPcfi8j1wPeWT71cVb8atVdzwmCozoMlFCp/cnPA6kr7G2ejP/Cq+xLSJN7sT185vaPd3iBKoM9lsHaZ/ftQfP/1x47thpoWN4kZq4Em6aODaGIxayCO5YJpaqmGFu3GYhVxP50qTi2URQWvidyXueOhjb7Tkv8qD673goiFr4UQ0g3VRChVi4t8f+Ciag863LjrvUGUjCjXasIufWzDNFGIWe0Y3CceJ3uDbX7qkMxcEOkYT2uKi+uzSmg3aNMJX4yU+UlYbagZ+MQgQg0cvgvsQprmTW+aGIOX66w9xuzeNbttMNCowdYHNyZfh2ub/ajxAtcZbsxV9DM3HYv0mTe9lkZWdSiaWxZp9qYzsZiBjy86VPqs740QVCwann9od9Bmvz4TakSMuEGTY8Yo9wKFK2zaYDwcNhd0V3ozijeOEzPQnkMsmrqVVGEtYF+aWPTF69NkRM0UCxHpisjnkvRkDvEZ+EMNWr5uqCLvP8zF0/RcQs/ucw/WTY4ZK8hd5woNnYE3Imfq6Ii61fO9fvitAVTV6zoOde03zcQq2p4DsVDVAXCbiFyQpDdzhs8AcHJzECSVrc2saVYtpSY0vQFCD5hNxDqKG6rBMUMvyBxRJwaxLJomAhBrhu/Sh5AzeigmaT73b6hr38eVO6oiEBuXaORZwC0i8nHgxOhJVb04Wq/mgPXewHs3soc2+hxabVf6oo07KUTpjZ7DYrhx1jb7QTOiGlkWgcVivTeYuf/0zvbjzPAfODn7vB44GafdJq6NjXKA7QbOhJtVE2zE+uaAM/aGKzPjO+iHmiz4ZLgNh4Vgx86Icjn6L0XtwZzSZqZ6IoBYtLIsAsy2fC7+4bCY6YWqj9Xkxh0ETFtu2jacsihDD5jHa8TggfVelJTl5n7zPgcDDtrFMR3SlgO7wHzFIpRl6y1WG/3oYlEb4FbVDwFfBJbLxzcAp/1eFm2CRk1vtHGmlXdwJYRbIPcMS1V5qOFsPeTsvul5qIZ3w/UGw9pBaDiMk7rbNA4RI27h5IYKnAnke/2ubQ6CxE98RSdF3MKlkOD/BbwbeFP51LnAn8bs1DzQRizafnFtLYMQq7h9feFNB/hprG02X5QY8obxyoQLPGjXWRVbr1sL74pqev3HyMpyGThDi1SbCUeI689fLOKnz7qkzr4YeCLwAICq3g78o5idmgfarBlom8rWdrAP4YbyPf+HAg3YPhd/yCCzj1iGDnIfcxSBYyc3g7bbGwwb75cReoYPbsHrkCI1K03ZhbYFLV0rBkxse07EYkNVt65GEVmi2CnvtKbNRdM2O6G9ZdHu/arqPfCFSuXMObMfNizzcqr9sDP8Y2tuIuAqKq74DFihZ/jrvYGTK3a0n0kITmw2r9hQpe1kod0ENX5GlItYfEhE/hOwKiJPBt4F/FnUXmVmOGy3IrftHgdtyz63rUR5suef/rvRC3Pz+gz8o2ystvgOGqGsKihmma4Vjzf7w6AzSx+hDO2GaiI+oWpktR3s204W2riShsP4i/NcxOIVwL3AZ4CfBt4P/GLMTuVm2oYrTWgjNiEW1bU5RtuBJ4Q7xqcPoVbS+vqee/1hsAWRx0/2GsVs7j8RzhXlM+iEnOFDs1l2qDIzbf3+bScLbduPHbdwqTo7FJGrgI9RuJ9u0xQrQDISIpuoTXG1EBvKbPSG7Fvxe2/7GVafs/Z7Nk5h2fm6NU5s9Fun7rYRyxMbA/YstU/fva/h4H//2ibnn72vdbvgP1Nf2xhwaF+YCkJNBCtUvKTtJGk0WfD9/luLTW7LQkSeCXweeCPwu8AdIvL0qL3KTIgAcRsfbojN6NsITtusjrYzvZO9gbdlF2J21XaNTQhc4xUj7g8Yt/D9/kIWkmwycIfKggvhxmlz37etXhvbsnCZBvw28IOq+gOq+q+AHwRe79pAWV/qkyLyvvLvC0XkYyJyh4i8Q0RWyuf3lH/fUf7/cOUYryyfv01EntrkBH0IYVm0yWjaDGDON81mqdL2ps8pNiFu+DbthxgwB0N1Tpsd0QsYt/Ad8EL6zJsMfCEGybZxyq2+eH4Gw6G2HnfmIWbxoKreUfn7TuDBBm28DPhs5e/XAq9X1W8F7gcuK5+/DLi/fP715esQkUcBzwe+k2L/798TkTg7rZSEmdn7XzRNykxMY3Pg176qXyZQldbvbyE2bQcO1XaDRogb9tjappdlFSJusd4iuSGUO8hl3/UqIUqEr/f9rdltffH8DEK0HyN9ucpUsRCRHxGRHwGOisj7ReQFInIpRSbUDS4HF5HzgGcCby7/FuCHKBb5AVwFPKd8fEn5N+X/n1S+/hLgalXdUNUvAHcAj2twjo0JE2D2G/BDWBUAm33PbKb+0GuHvm3H8CzGNqLV6vmWs7Ni4PF/f4jMHF+X0v0NXVeTaFe5INQam+Ylwlu7PgP13XdDphCfXX+grTwKdcyKBD678vgfgH9VPr4XWHU8/n8F/iNwsPz7YcAxVR19s3dRrAin/P1lAFXti8jx8vXnAh+tHLP6ni1E5HLgcoALLmhXJDdIgNnzGHS6+DAAAB1sSURBVKEySnyPE+qGb1Mr6KRDAblpDAbaKsjYdtBYD7C9bNN4xan3tY9btJmdhhpwfRa3ndgYtKpNFapyru9OlcHEqjdgZSnONkVTxUJVX9jmwCLyLOBrqnqjiPxAm2O5oKpXAlcCHDlypJVBF0Kde/2h16DRa1ETavtx/M4h1E1zsud/87YVrJOb/mIRJMjZYnvZYYP1FeNs9oesbbYrKNdm0BqUfv+2+3F7rd5v6X4MMUEEfxd2qE3LNnoDaFnEdBq1V5WIXAi8BDhcfb1DifInAheLyDOAvcAZwBuAM0VkqbQuzgPuLl9/N3A+cFe5SvwQ8I3K8yOq7wmOqgab3W8OhuztNLtxQm3m4is64S5a382bmm/+Mk6btOUgmXAtxKKoIuvf9rG1XiuxaF+qpr1Y+Az8bWNVodw3vrHCUGIVoi7cNFzslT+lqDr7OxSZUaOfmajqK1X1PFU9TBGg/mtV/Qngg8Bzy5ddCry3fHxN+Tfl//+6XM9xDfD8MlvqQuAi4OMO/fZic9B+Qd4IH9HpBdrLt+854oQI7oN/3MfXjN92jBbnEOJmayM4dftX1NE0i2qcecjIybFTXagJ4nCIV7wu1GJOX7FywWUKsq6qbwzY5suBq0XkNcAngbeUz78FeJuI3AHcRyEwqOotIvJO4FagD7y43MEvCr4bHk3CZ7bSpjR5Fd/zCHXR+g66IXy3bY6RW6x8XVBb788sFm3f77PpFhQi1WY/kX6gSRoU59Bt6FHYDZaFi1i8QUSuAP4K2Bg9qarOe1qo6vXA9eXjO5mQzaSq68CPTXn/rwK/6tpeG0KWLPC5AH0tgnEGQ0VVKRLK3AkVM/HN6loPcNO0GfBDuKFaWRYtxeJEi90K6/a8dqGt2LdaELnZ9941L8RWyG2OFeq+Cyl647iIxXcDP0WR8jq6k7X8+7Qj1JcGfl9cyIu2P1SWu03FIoxYeVs2AQZrX1eaapjUQ1+hbFsiGwo3yAnPTLQwVlW+khUnNvzFIkQByq1jefixw8Uq81oWPwY8slqm/HQm6GDt8cWFnBkMhkrTWGM4sfCMmQRJW/YsBDjQIPEqX7FqWyJ76zieaaRhrKp231+uUish5+NNb+HhMMx1B2HHr3FcAtw3g3dyya5jELBGos8XF/LL9pnh+LxnEr6fYwix6A/Ua6YYakGkd9pywDUuPoSqXNCmzmjbIo7zQEPPb/AJYixcLIszgc+JyA1sj1nUpc7uSnKboyHr+TY9FVVtvXp7hO9FGy6FsXnacogyK1CIhU+8KNyCSM9MtACWhWoh+L7ps7lKvfgvoWx/rFATtNDHGsdFLK6I1vocknOwLt6T78IJOSnxPY1QbjCfAStU26p+8aJga1w83XDBFqZ5ikV/MGz1GZxssXq+zYr7HcdqaloEJObmES77WXwoXvPzh2beMTaoWDQc/UNuU+L7OeZ0BYVa4wKFK6zpeJl7FXGo9n2tw7Z1vUabX/nsZ+Kbchv7WPOEywruBzkV/1kBloETqnpGzI4tKiGlqunY39RtEprhULOuMwnVNoxSoPNYNr6Cm7v9EEUY1zw3v1oKOMCHPFZTYt7CLpbFqAgglSqwj4/XpcUmpBnZ9FBh/bbNjxZ6YVTz9sOlHfrl2odLW/aJmYSKF/nGfkKU2PaN1yx3wxTf63RgqeGxQrqtYrrAGp2VFvwpEH0DolyE/eJ83pXPDRbyOvM5VsjBeh7WuORs3+dQoT5/3+OECPDnFguf44Q0RGKKhYsb6keqfQGOAOvRepSZkIGu3G6dpjEIEaHTIUhGlI/fNncKYcgAv09WXcj2m5a+GAzDZcLlLGLpW25kT6Cy3iseYrFb4iUuzr3qvhZ9iqKCl0TpzRzQDTjA5/Rd+tLtdBgGGDV8LtqQacv517g0f0/OBIPcLjgItZ2xp1gshxGLPR5ZYCLCUleC1KVbapiB1+jYdS9ou6/FbiPkh93UdzkPLHWE9lvowFKn+bnnrs8TMhMud1ZdU3K74EKUpgf/tGHf/U/G2espOivdDv0AFWN9LBtXpoqFiPzyjPepqr46Qn+ys+wxyE0/lo/w5HWDhbKGfEQ3qBso84JIn2MV/uYwnWjquw7tAmtKqJTp4bAI1DfdLW615R4cI/Z6is7yUgcCxGxi7ZIHswPcJyb8AFxGUWb8tCTkh+0T7AoaZPZ4z3JG321IN0xufM4kZHCyqTs15Poen+8x1BqP4ljNB92VpQ7dAF6FfSt+YpEzZuLKrG1VtzY4EpGDwMuAFwJX47D50W4lpFj4+EGDpq96HCzUxebzOYYt5pZXeHy+x1DBSZHmiRoasFipj5USKm0X/APsq8tdHhq0S9/d6y0WYSybULGXScw8soicXW5SdBOFsDxWVV+uql+L1qPMdDsSLG7hcwGEzKDyOVaoGY6PVZXbsMidOty0PMg0fGJluWMsIQPsvutV9rfYjnbEPk93lm+sY5xQ7rRJTO2hiPwWcAPwIPDdqvorqnp/tJ7MEW33EIbCZ+8zUwyZQOVlWQQSi1Ci44uP8PgsJAx5rHC5/rsvCy/kDpW+KdirnlbBiD3LHe+klmAxkxxiAfw88M3ALwJfEZEHyp8HReSBaD2aA0J84L5ffk6/NQQ0hz3EIvfMPmBug5fohxILH1diUKH0WpAZMBPOU3j272l37e9rYZm0FSoort+Yk7RZMYvdl/cZiBAq7/vlhxwwfYQnlDnsI7hhg/vNDxZyjY3P4s5wVp3HZx/wbvf5FEPGmHz3Umkz2EM7sWnbNsDq8lLUhcALKwiz8M1oCHGMkCswfa6bUGasl2WReXYb8rP3SUEOJdQ+Qc6gZW48zj1s2rKnZdHyvm8T8+h2pPW919YyqsPEYgIhTMJVzwsn5OzWZ/Bb6XZaz/CXuuLluw0Zr/E5d5+FhCHbDyXUPrn+Qa+7zGVufFnqdlp9Bz7Vbqvsy+gGc8HEYgIhsiJ8Zykha1P5zG47HWkdt/B14+WukRNy9b5P/CGYWKycvvWJXGjjijmw1//ebzvYtxWbtu+vw8RiAnuXO62Dnb4qH2oFdafjf9Osegw2VXwHvdwDVqgAs++xQmXE+Bwn6H4OHqIb8rtvc6gDngP+8lKn9SSrtVi0EDoXTCwmICKtTLrlpY53sDLUTdNtoXZtZ7i+bryQg7XP4BcqwNzt+KVNdzsSZFGVj1h0PPs8CR93XtDkghbH2u85YIeY1fu2DcXk0HeNh3MbUY++i2nz5bcJlIXym7eZKbad4fq+P+zstvnnGCrtsM1x2n72K0v+uf45U3dzuwBH+N73IcTiwJ4l73jh/pWloC7sSZhYTKGNyrd5b6ibppVYtAzw+75/qdve/TfCZ2FazlInI9oGKdtk8oWyrHyOE1YsWlgWK34DdggXULfj79E4uHe5dft1mFhMoY110GaWEarqbZvy6LksC8g7u+10JMiA2caNl3NhWE6x2NMN50JpUwyz4zlgHwiUiXTQU3R839cEE4sp7HbLos3sqrVl0WKwzD27D5E23Wa9RM6FYTndcCEL4LU9D5/JXqjg8hmeFoKJRUb2rXS9XSJtbticewGP2LPU9Q527l3utvKd5lzFDKFW77eZaOSzLIKl7nocZ89S+/U9UCYJtM1Kajjw7lvxv1/G8R30Y6fNgonFVHwzotqm0IUqAtdWdHxn2G1n5jmLOIZqv43grC77T1Kg3aARQiiXlzpen71I+xXMEMZCafoZtvEk7GjbQyz27ekm2ZXTxGIGXuZoy5mhiATZgKitKe4bKG074IQYMHLGDKBdkLlN2nZRMqJNynSetN2t9wZwAYZYUNt0dh9yfcNyt9P4+vF1XTXFxGIGPjOGELOMEH77tpaF74DXdrAN4gZqcYy2MYMQNX58rYP9e9oVkgtS5iZjuQwII/Z7l7uNds07GNgF1FR8UsQrwMRiJj4XXoiZTQi/fVvLwtfvnjM4HqIPbYvJhShCmSvXf89Ss0FyEq0++8wL26o0EYDQK6ebpsGmSJsFE4uZ+Lmh2l84IbJS2vpufVeDtp2Z557dti4mF2Dg8D1GiGuv7SrgNn0ItbAtBK6i0+1I8N3pGrvBEgS3wcRiJj7BxhAzmxC+49bFADPFLFaWOq1jNm2/gzaujJwDXgihavvZtSmm12YFMxQlL0JY9qO+uNDW9dembSgmhaEyCOswsZhB02Bjm5pQVdoO9G2ygUbsXW6eDujznknkdgW18QGHEIu9y10vwQzhu24ttC33dGjT/oE9y8FKXrh+ljH2kGjy/aeyKsDEopYmX0bbTKgRbQOkofLlm1oXIVxI0H5RY/sAs78POJT/uunAv3e5G2SNTqvU2wDrDdpk9pyxGm7gdL0GD7a4Vmbh+j2kCm6DiUUtTQauUMG1tm6oUD7UprPEEMFdaDdghbh5fI+xEqBM9VYfGn4GoQaN3DGHQ/v8B99Dq+EG7uVuxynuF2t3Otfvs83EpinRxEJEzheRD4rIrSJyi4i8rHz+bBG5VkRuL3+fVT4vIvJGEblDRG4SkcdWjnVp+frbReTSWH2eRJOLIZS/tHVtpkCDdtPjhDr/dm6g9jeP74rckLO8phkuoSya1RX/jKgQfWgz4IcUC3Cb/IVckFfFdeIVeyvVKjEtiz7w86r6KODxwItF5FHAK4DrVPUi4Lryb4CnAxeVP5cDvw+FuABXAN8HPA64YiQwKWjmhgpz4Sx128U+glkWDS/EeXBDhRiwRMTrOCFTGJsKT1Ch8vz8g8RMVrpe9dGWlzrBtxWtu59DuDx92x4ReyvVKtHEQlXvUdVPlI8fBD4LnAtcAlxVvuwq4Dnl40uAP9SCjwJnisgjgKcC16rqfap6P3At8LRY/R5ntUHQNuQso41LJ9SgvW+5admDMO36rGIdcUammEHItqG0bhoMmiFX8fqKXgj/vYh4WQhnBrYqoP4ejGVVFG3XHztEjKgJSWIWInIYeAzwMeCbVPWe8l9fBb6pfHwu8OXK2+4qn5v2/Hgbl4vIURE5eu+994bsu9PAtRIoE2pEmwE/VOygSRpkpxPOogE4w+PmD5k66TNghrQsRMR5hr+81G5tyDg+QrnUlWCTlDP3rXi8J7xY1M3uQ11rkyg2sZotBKE+b1eii4WIHAD+BPj3qvpA9X+qqoCGaEdVr1TVI6p65JxzzglxyC1cXBKhV3H6mpchB+3lrvuah73L3aD55j4z5YN706dOjgg5WI5wFcyQFg34iUVIoTzLY+D3EZg66u7BUJMy3/ZjitUkooqFiCxTCMXbVfU95dP/ULqXKH9/rXz+buD8ytvPK5+b9nwyXPyHofOdfV06q8thFwm5rnkIfeH6pEGGdMUcWFlqtCAzRgqj6zFDl3s4sGepsXvjUMC01TP2Ljf67LsddyusCXWz+zYLEF2oE6PQK8friJkNJcBbgM+q6usq/7oGGGU0XQq8t/L8vyuzoh4PHC/dVR8AniIiZ5WB7aeUzyUjR1aE7+AbOjvC1cIJ3e7BvcuNV/OGzIZpumNajPo8rscMub4AShdY4wB72M++ifAf2hfOohxn1n0de2Zf51rcu5J25UPM1p4I/BTwQyLyqfLnGcBvAE8WkduBHy7/Bng/cCdwB/AHwM8CqOp9wKuBG8qfV5XPJSOHZeG7+VIuCyd0Vka3I43PJXTqZJMBM4Zlsd8xgBmjRHXTmFHoPjRxK8UIbo+YNXuPPbOvc2umtiyiSaOq/k9g2pX+pAmvV+DFU471VuCt4XrXjL3LRTpffzA9vBJ6kB6VGnlovd/ofeFFy9GyiDDLOrRvmQcdz39lqRM+ZrB3mXtYd3ptDMtiNMM/ttab+prQwe0RTQb/5QiffZOAdYx4xYhprqC2O0K6sLcmXnjauKFON2bNHENuq1gl517AI5wtiwj+2zNX3QeB0FYFuH/+nU77aq3TqBOhWOUemhw3dIAdiu/TxQ0pEue7HzFNBFNkIs1qY6krSXbHq2Ji4cislcGhB+gRTQeCGOWSXSrvrix1gu0dXqXJIBBFLFyLya0sRZtl1l0DsXZJ29dgcZxPmnMdy92OUxzwjNXlqGsNpt1PKWb1s0rHhCor0wQTC0dmDRyxFuf4lHwIXS5ZRFitWZwXq+TA6krXee1KDLFYdtzbItZkAerFIpZlUbjAXFN34wiWiysqZrwCpgeZU1gW3Y5MFewQe403xcTCkVkuiRhpe3Vthni9K3ViELPkgIsIiMSZ3YKbEMSqPAojq2VG2xGFyjUdNnQ21ggXN2RMFxQUG5FN+vxD7Dnj1v7key/EBmlNSbuqY5fyvDd9BID71zYB+PJ9awD85gc+BxQXbEeEd/z0E4K2u1IGL1/1vlu2PT/e/oj//sLHBW1/RCEGG1P/HzOF8NDqMvc+OL1tKCywWK6IA3uW+HpN+zGLuXU6wv6VpYmB/m43vNuxiovFsHe5G80l8pI//gTHT54K7k+67g+tLvOun/nnUdqHwsLau9RlbXOw7flUweWVpQ4nJlx+OdxQJhYNOLhnCQW+4xFnbHu+E9j1U+W7zz20w2IYb3/EOQf2ROlDrWURcbB0cUXEnF26WGsxawRBYd1MEosDEXZpq+JircW0bDqyPX16/LoX4t57I/Ys7xSLVIP1NAvCLIs5JbTF0IRD+5Z5z88+MVv7kLfswGhxns4oChNTLOqEMmbl0REH90xO4Y29S9pox7Zefzj1NbHcf5D3vqsyaWBONVhPayfVVqpVLGZh1DKr7ECnE9d/67I4L5bPHAohnDV5TbGt5TTBStF2rgD7PDF+fa8sdaKvsRgxLctwJXHaLJhYGA4sz9hfI3QtqknMmr0udZuV5WhKpyYdOcV+AtPcXLHdX1Aft1gEsRh3OaV0AU2778yyMOaWabPb2JU3YbZYxHSDjNg3Y1BOMbsfVRAYJ8UuabPEYM9yuG1k55lxcdiTcOX0NFGIsa6pDhMLw4lpay1SDFizVgjHyvGvMqvybqo9BcatiKWuJBmoZ4lFjBIn88j4gJ3SBTRJFERg2XPr2zaYWBhOTLMgVlO4YWasNYhRamKcWYKQag/kcVdYqu00Z+0UmcKqmgfGRTmlC2iSy2u524nu+p2EiYXhxDSxiFUTqcporcEkUsxup7UdenfAWYx//incfzB7P/JFEYtxcUgZs5hkWeRwQYGJheFIzoJqMFkUul1JspJ22jmG3h1wFuOWRMotNaeJZcwyJ/NEtyPbrKuUlsV426nbr2JiYTgxaQbd6aSbZU2axR6MvChtxN4prphUriDY+fmnLE896bMXSWNVzgvVATp12uq4JZEjbRZMLAxHliakz6acWU+KDSQdrCfM5FO5gmDnrmgpxWLSZ7+6En8/h3miOmC77ksfivH7bnkpz+cuOmtp7C7lyJEjevTo0dzdOG0Y1cZ6aKPPnfeeAOBbHraPpY5sZenEWm07anuoyoPrfb70jbWt9ou6RJ0k7a9t9ukNdFv7q8unquLGbh/g+MneVvvfde4ZW6UuYq50ft6bPjLxs1/qnoojzctK69BUP/sTm30+/7Xi2v/ucw9tLdSM/dkDnNjo8/nKfbensuFV6PZF5EZVPTLpf4vhdDSCcGDPEo8+71CWtjsiHFpdztb+yIrJ1T6Q7fxzf/bzwP6VfNf+/oz3XRWzLAzDMAxgtmVhMQvDMAyjFhMLwzAMoxYTC8MwDKMWEwvDMAyjFhMLwzAMoxYTC8MwDKMWEwvDMAyjFhMLwzAMo5bTclGeiNwLfCl3PyLzcODruTuRiUU+d1js87dzj8u3qOo5k/5xWorFIiAiR6ettDzdWeRzh8U+fzv3fOdubijDMAyjFhMLwzAMoxYTi93Llbk7kJFFPndY7PO3c8+ExSwMwzCMWsyyMAzDMGoxsTAMwzBqMbGYY0TkaSJym4jcISKvmPD/7xeRT4hIX0Sem6OPMXE4//9bRG4VkZtE5DoR+ZYc/YyBw7n/jIh8RkQ+JSL/U0QelaOfsag7/8rrflREVEROm3Rah+/+BSJyb/ndf0pE/s8kHVNV+5nDH6ALfB54JLACfBp41NhrDgOPBv4QeG7uPmc4/x8E9pWPXwS8I3e/E577GZXHFwN/mbvfKc+/fN1B4G+AjwJHcvc74Xf/AuB3U/fNLIv55XHAHap6p6puAlcDl1RfoKpfVNWbgGGODkbG5fw/qKpr5Z8fBc5L3MdYuJz7A5U/9wOnU6ZK7fmXvBp4LbCesnORcT335JhYzC/nAl+u/H1X+dyi0PT8LwP+ImqP0uF07iLyYhH5PPCbwEsT9S0FtecvIo8FzlfVP0/ZsQS4Xvc/Wrpf3y0i56fomImFsesRkZ8EjgC/lbsvKVHV/6aq/xh4OfCLufuTChHpAK8Dfj53XzLxZ8BhVX00cC1wVYpGTSzml7uB6ozhvPK5RcHp/EXkh4FfAC5W1Y1EfYtN0+/+auA5UXuUlrrzPwh8F3C9iHwReDxwzWkS5K797lX1G5Vr/c3AP0vRMROL+eUG4CIRuVBEVoDnA9dk7lNKas9fRB4DvIlCKL6WoY+xcDn3iyp/PhO4PWH/YjPz/FX1uKo+XFUPq+phinjVxap6NE93g+Ly3T+i8ufFwGdTdGwpRSNGc1S1LyI/B3yAIkPirap6i4i8CjiqqteIyPcC/wM4C3i2iPxnVf3OjN0Ohsv5U7idDgDvEhGAv1fVi7N1OhCO5/5zpVXVA+4HLs3X47A4nv9pieO5v1RELgb6wH0U2VHRsXIfhmEYRi3mhjIMwzBqMbEwDMMwajGxMAzDMGoxsTAMwzBqMbEwDMMwajGxMHYtIjIoq27eLCLvEpF9ufsEICL/KXcfJiEibx5VpxWRL4rIw3P3ydg9WOqssWsRkYdU9UD5+O3Ajar6Osf3dlV1ELtfDd4TrT9T2vsiRaXWr6dq09jdmGVhnC58GPhWABH5UxG5UURuEZHLRy8QkYdE5LdF5NPAE0Tkl0XkhtIyuVLKlX0icr2IvF5EjorIZ0Xke0XkPSJyu4i8pnK8nxSRj5fWzZtEpCsivwGsls+9fdrrJvVn2omJyH4ReWt5jE+KyCXl8y8QkfeW/b1dRK6ovP7PReTT5bk9r3JeO0piSLEvyM3lz78vnztcnvsflJ/jX4nIaruvyNjV5K7fbj/24/sDPFT+XgLeC7yo/Pvs8vcqcDPwsPJvBX688v6zK4/fBjy7fHw98Nry8cuArwCPAPZQVAF9GPAdFAXdlsvX/R7w76r9Kh/Pet14f15FUbZi/Dx/DfjJ8vGZwN9RlCV/AXBP2Z/RuR4BfhT4g8r7D1XO60j5+IvAwynqCn2mPN4B4BbgMRR7pfSB7ylf/85RH+xnMX+s3Iexm1kVkU+Vjz8MvKV8/FIR+dfl4/OBi4BvAAPgTyrv/0ER+Y/APuBsioHyz8r/jUpKfAa4RVXvARCRO8tj/guKgfaG0iBZBSbVp3rSjNdt64+q/vKU83wKcLGI/D/l33uBC8rH16rqN8q+vafs1/uB3xaR1wLvU9UPTzku5ev/h6qeqBzjX5bn/wVVHX2+N1IIiLGgmFgYu5mTqvo91SdE5AeAHwaeoKprInI9xeAKsK5lXEBE9lLM8o+o6pdF5FcqrwMYVfUcVh6P/l4CBLhKVV9Z08dZr9vqj8MxflRVb9v2pMj3sXPTI1XVv5Niv4dnAK8RketU9VUO7YxTPe8BhdAZC4rFLIzTjUPA/aVQfDtF+epJjITh6yJyAGi6h/l1wHNF5B8BiMjZcmoP8J6ILDu8zpUPAC+pxFQeU/nfk8tjrlKUKf9bEflmYE1V/4ii2OJjZxz7w8BzRGSfiOwH/nX5nGFswywL43TjL4GfEZHPArdRlK/egaoeE5E/oPDzf5WiNLQzqnqriPwi8FdSbMbTA14MfAm4ErhJRD6hqj8x43XbmFFV9dXAfy2P2QG+ADyr/N/HKVxZ5wF/pKpHReSpwG+JyLBs70UzzuMTIvL/lccBeLOqflJEDjf5PIzTH0udNYxdioi8gMKN9nO5+2Kc/pgbyjAMw6jFLAvDMAyjFrMsDMMwjFpMLAzDMIxaTCwMwzCMWkwsDMMwjFpMLAzDMIxa/jeL44kuKjz5TgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "def run_statistics(strategy, update_mode, parameter_name, parameter_list, number_tests, steps, games):\n",
    "    out = [[] for i in range(len(parameter_list))]\n",
    "    for index,parameter in enumerate(parameter_list):\n",
    "        print(\"parameter: %0.2f\" % parameter)\n",
    "        for i in tqdm(range(number_tests)):\n",
    "            if parameter_name == 'epsilon':\n",
    "                player = Player(strategy=strategy, update_mode=update_mode, epsilon=parameter)\n",
    "            if parameter_name == 'UCB':\n",
    "                player = Player(strategy=strategy, update_mode=update_mode, UCB=parameter)\n",
    "            if parameter_name == 'step_size':\n",
    "                player = Player(strategy=strategy, update_mode=update_mode, step_size=parameter)\n",
    "            out[index].append(how_many_iterations(player,steps,games,verbose=False))\n",
    "    with open('statistics_%s_%s.bin' % (strategy, update_mode), 'wb') as f:\n",
    "        pickle.dump(out, f)\n",
    "    return(out)\n",
    "\n",
    "parameter_list_eps_td = [(i + 1) / 20 for i in range(10)]\n",
    "parameter_list_ucb_td = [1 + (i + 1) / 10 for i in range(10)]\n",
    "\n",
    "#run_statistics(strategy='UCB', update_mode='TD', parameter_name = 'epsilon', parameter_list = parameter_list_ucb_td,\n",
    "#               number_tests = 50, steps = 250, games = 50)\n",
    "\n",
    "def print_statistics(name_file, parameter_list, name_parameters):\n",
    "    with open('%s.bin' % name_file, 'rb') as f:\n",
    "        out = pickle.load(f)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.violinplot(out,parameter_list,widths=0.03)\n",
    "    ax.set_xlabel(\"Parameter: %s\" %name_parameters)\n",
    "    ax.set_ylabel(\"Number of iterations\")\n",
    "    plt.savefig('%s.png' % name_file)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "print_statistics(name_file='statistics_epsilon-greedy_TD', parameter_list=parameter_list_eps_td,\n",
    "                 name_parameters='epsilon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
